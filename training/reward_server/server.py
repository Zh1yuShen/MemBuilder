"""
Memory API Server for RL Training.

A Flask-based API server that provides memory construction and QA evaluation
for verl-based RL training. This server runs on CPU and is called by the
reward function during training.

Usage:
    python server.py --port 8765 --api-key sk-xxx --base-url https://api.openai.com/v1

Endpoints:
    GET  /health          - Health check
    POST /build_and_qa    - Build memories and evaluate QA
"""

import argparse
import json
import os
import time
from pathlib import Path
from flask import Flask, request, jsonify

# è°ƒè¯•æ¨¡å¼ï¼šè®¾ç½®ç¯å¢ƒå˜é‡ REWARD_SERVER_DEBUG=1 å¼€å¯è¯¦ç»†æ—¥å¿—
DEBUG_MODE = os.environ.get("REWARD_SERVER_DEBUG", "0") == "1"

def debug_print(*args, **kwargs):
    """è°ƒè¯•æ‰“å°ï¼Œä»…åœ¨ DEBUG_MODE=True æ—¶è¾“å‡º"""
    if DEBUG_MODE:
        print("[DEBUG]", *args, **kwargs)

try:
    from config import EMBEDDING_MODEL, ANSWER_MODEL, JUDGE_MODEL, QA_ANSWERING_TOP_K
    try:
        from llm_client_internal import OpenAIClient
    except ImportError:
        from llm_client import OpenAIClient
    from memory_system import MemorySystem
    from eval.llm_judge import evaluate_answer
except Exception:
    from ...config import EMBEDDING_MODEL, ANSWER_MODEL, JUDGE_MODEL, QA_ANSWERING_TOP_K
    try:
        from ...llm_client_internal import OpenAIClient
    except ImportError:
        from ...llm_client import OpenAIClient
    from ...memory_system import MemorySystem
    from ...eval.llm_judge import evaluate_answer

app = Flask(__name__)


# Configuration - set by command line arguments in main()
SERVER_CONFIG = {
    "embedding_model": os.environ.get("EMBEDDING_MODEL", EMBEDDING_MODEL),
    "answer_model": os.environ.get("ANSWER_MODEL", ANSWER_MODEL),
    "judge_model": os.environ.get("JUDGE_MODEL", JUDGE_MODEL),
}


_ANSWER_CLIENT = None
_JUDGE_CLIENT = None


def _get_answer_client():
    global _ANSWER_CLIENT
    if _ANSWER_CLIENT is None:
        _ANSWER_CLIENT = OpenAIClient(model=SERVER_CONFIG["answer_model"])
    return _ANSWER_CLIENT


def _get_judge_client():
    global _JUDGE_CLIENT
    if _JUDGE_CLIENT is None:
        _JUDGE_CLIENT = OpenAIClient(model=SERVER_CONFIG["judge_model"])
    return _JUDGE_CLIENT


@app.route('/health', methods=['GET'])
def health():
    """Health check endpoint."""
    return jsonify({"status": "ok", "message": "Memory API Server is running"})


@app.route('/build_and_qa', methods=['POST'])
def build_and_qa():
    """
    Build memories from model actions and evaluate QA.
    
    Request JSON:
    {
        "session_group_id": "conv_001_session_0",
        "state_before_path": "/path/to/state",
        "memory_actions": {
            "core": {"operation": "APPEND", "content": "..."},
            "episodic": {"operations": [...]},
            "semantic": {"operations": [...]},
            "procedural": {"operations": [...]}
        },
        "qa_questions": [
            {"question": "...", "answer": "..."},
            ...
        ],
        "new_session_messages": [...]
    }
    
    Response JSON:
    {
        "success": true,
        "task_reward": 0.8,
        "correct": 4,
        "total": 5,
        "retrieval_counts": {"episodic": 3, "semantic": 2, "procedural": 0},
        "dominant_agent": "episodic"
    }
    """
    try:
        request_start = time.time()
        data = request.json

        session_id = data.get("session_group_id", "unknown")
        state_before_path = data.get("state_before_path", "")
        
        debug_print(f"\n{'='*60}")
        debug_print(f"ğŸ“¥ æ”¶åˆ°è¯·æ±‚: session={session_id}")
        debug_print(f"   state_before_path: {state_before_path}")

        # New scheme (original pipeline)
        memory_actions_list = data.get("memory_actions")
        qa_pairs = data.get("qa_pairs")

        # Backward compatibility (older dict-style request)
        memory_actions_dict = data.get("memory_actions", {}) if isinstance(data.get("memory_actions"), dict) else None
        qa_questions = data.get("qa_questions")
        
        # è°ƒè¯•ï¼šæ‰“å° memory_actions æ‘˜è¦
        if DEBUG_MODE:
            if isinstance(memory_actions_list, list):
                for item in memory_actions_list:
                    agent = item.get("agent_type", "?")
                    action = item.get("action", {})
                    if agent == "core":
                        op = action.get("operation", "N/A")
                        content_len = len(str(action.get("content", "")))
                        debug_print(f"   {agent}: op={op}, content_len={content_len}")
                    else:
                        ops = action.get("operations", action.get(agent, {}).get("operations", []))
                        debug_print(f"   {agent}: {len(ops)} operations")
            debug_print(f"   qa_pairs: {len(qa_pairs) if qa_pairs else 0} questions")

        answer_client = _get_answer_client()
        judge_client = _get_judge_client()
        
        # Initialize memory system
        memory = MemorySystem(llm_client=answer_client)
        
        # Load state_before if provided (critical for QA evaluation)
        if state_before_path:
            # Handle path prefix - try multiple base paths
            candidates = []
            if state_before_path.startswith('/'):
                candidates.append(state_before_path)
            else:
                # Relative path - try project root
                project_root = Path(__file__).resolve().parent.parent.parent
                candidates.append(str(project_root / state_before_path))
            
            for candidate in candidates:
                state_path = Path(candidate)
                if state_path.exists():
                    try:
                        memory.load(str(state_path))
                        debug_print(f"   âœ… åŠ è½½stateæˆåŠŸ: {candidate}")
                        debug_print(f"      core_memory: {len(memory.core_memory.human) if memory.core_memory.human else 0} chars")
                        vec_count = len(memory.vector_store.memories) if hasattr(memory.vector_store, 'memories') else 0
                        debug_print(f"      vector_store: {vec_count} memories")
                        break
                    except Exception as e:
                        debug_print(f"   âš ï¸ åŠ è½½stateå¤±è´¥ {candidate}: {e}")
            else:
                debug_print(f"   âŒ state_before_pathä¸å­˜åœ¨: {state_before_path}")

        # Apply actions
        memories_before = len(memory.vector_store.memories) if hasattr(memory.vector_store, 'memories') else 0
        if isinstance(memory_actions_list, list):
            _apply_memory_actions_list(memory, memory_actions_list)
        elif isinstance(memory_actions_dict, dict) and memory_actions_dict:
            # Convert dict-style into list
            converted = []
            for agent_type in ["core", "episodic", "semantic", "procedural"]:
                if agent_type in memory_actions_dict:
                    converted.append({"agent_type": agent_type, "action": memory_actions_dict[agent_type]})
            _apply_memory_actions_list(memory, converted)
        
        memories_after = len(memory.vector_store.memories) if hasattr(memory.vector_store, 'memories') else 0
        debug_print(f"   ğŸ”§ åº”ç”¨actionså: +{memories_after - memories_before} memories")

        if qa_pairs is None and isinstance(qa_questions, list):
            qa_pairs = qa_questions

        qa_pairs = qa_pairs or []

        correct = 0
        retrieval_counts = {"episodic": 0, "semantic": 0, "procedural": 0}

        for qa_idx, qa in enumerate(qa_pairs):
            question = qa.get("question", "")
            gold_answer = qa.get("answer", "")

            search_result = memory.search(question, user_id=session_id, top_k=QA_ANSWERING_TOP_K)
            retrieved = search_result.get('results', [])
            retrieved_texts = [r["memory"] for r in retrieved]
            
            # è°ƒè¯•ï¼šæ‰“å°ç¬¬ä¸€ä¸ªQAçš„æ£€ç´¢ç»“æœ
            if qa_idx == 0:
                print(f"   ğŸ” QA[0] æ£€ç´¢åˆ° {len(retrieved_texts)} æ¡memory")
                for i, mem in enumerate(retrieved_texts[:3]):
                    print(f"      [{i}] {mem[:80]}...")

            for mem in retrieved_texts:
                for mem_type in retrieval_counts:
                    if f"[{mem_type.upper()}]" in mem:
                        retrieval_counts[mem_type] += 1
                        break

            generated_answer = memory.generate_answer(question, user_id=session_id)
            score = evaluate_answer(question, gold_answer, generated_answer, llm_client=judge_client)
            correct += score
            
            if DEBUG_MODE:
                debug_print(f"   ğŸ“ QA[{qa_idx}]: score={score}")
                debug_print(f"      Q: {question[:60]}...")
                debug_print(f"      Gold: {gold_answer[:40]}...")
                debug_print(f"      Gen: {str(generated_answer)[:40]}...")
                debug_print(f"      Retrieved: {len(retrieved_texts)} memories")

        dominant = None
        if any(retrieval_counts.values()):
            dominant = max(retrieval_counts, key=retrieval_counts.get)

        task_reward = correct / len(qa_pairs) if qa_pairs else 0.0
        
        elapsed = time.time() - request_start
        # å§‹ç»ˆæ‰“å°retrieval_countså’Œdominant_agentï¼Œæ–¹ä¾¿è°ƒè¯•å½’å› é—®é¢˜
        print(f"   ğŸ“Š retrieval_counts: {retrieval_counts}, dominant: {dominant}")
        debug_print(f"   âœ… å®Œæˆ: reward={task_reward:.3f}, correct={correct}/{len(qa_pairs)}, è€—æ—¶={elapsed:.2f}s")
        debug_print(f"{'='*60}\n")

        return jsonify(
            {
                "success": True,
                "task_reward": task_reward,
                "correct": correct,
                "total": len(qa_pairs),
                "retrieval_counts": retrieval_counts,
                "dominant_agent": dominant,
            }
        )
        
    except Exception as e:
        # é”™è¯¯æ—¶è¿”å›ç®€åŒ–å¥–åŠ±ï¼Œè€Œé0ï¼ˆé¿å…å½±å“GRPOè®­ç»ƒï¼‰
        # åŸºäºè®°å¿†æ•°é‡ç»™åˆ†ï¼šæ¯ä¸ªmemory 0.05åˆ†ï¼Œæœ€å¤š0.8åˆ†
        fallback_reward = _compute_fallback_reward(data.get("memory_actions", []) if 'data' in dir() else [])
        print(f"  âš ï¸ å¼‚å¸¸ï¼Œä½¿ç”¨å…œåº•å¥–åŠ±: {fallback_reward:.3f}, é”™è¯¯: {str(e)[:100]}")
        return jsonify({
            "success": True,  # è¿”å›success=Trueé¿å…å®¢æˆ·ç«¯é‡è¯•
            "task_reward": fallback_reward,
            "correct": 0,
            "total": 0,
            "retrieval_counts": {},
            "dominant_agent": None,
            "fallback": True,
            "error_msg": str(e)[:200]
        })


def _apply_memory_actions_list(memory: MemorySystem, actions: list) -> None:
    new_memories = []
    for item in actions:
        agent_type = item.get("agent_type")
        action = item.get("action") or {}

        if not agent_type:
            continue

        if agent_type == "core":
            op = str(action.get("operation", "")).upper()
            if not op and "new_core_memory" in action:
                op = "REWRITE"

            if op == "APPEND":
                content = action.get("content", "")
                if content:
                    memory.core_memory.human = (
                        memory.core_memory.human + f"\n{content}" if memory.core_memory.human else content
                    )
            elif op == "REPLACE":
                old = action.get("old_text", "")
                new = action.get("new_text", "")
                if old and new:
                    memory.core_memory.human = memory.core_memory.human.replace(old, new)
            elif op == "REWRITE":
                content = action.get("content") or action.get("new_core_memory") or ""
                if content:
                    memory.core_memory.human = content
            continue

        agent_data = action.get(agent_type, action) if isinstance(action, dict) else {}
        operations = agent_data.get("operations", []) if isinstance(agent_data, dict) else []
        prefix = f"[{agent_type.upper()}]"

        for op_item in operations:
            action_name = str(op_item.get("action", "")).upper()
            if action_name == "ADD":
                mem = op_item.get("memory", "")
            elif action_name in ["UPDATE", "MERGE"]:
                mem = op_item.get("new_memory", "") or op_item.get("memory", "")
            else:
                mem = ""

            if mem:
                if not str(mem).startswith(prefix):
                    mem = f"{prefix} {mem}"
                new_memories.append(str(mem))

    if new_memories:
        memory.vector_store.add(new_memories, [{"type": "memory"} for _ in new_memories])


def _compute_fallback_reward(memory_actions: list) -> float:
    """
    è®¡ç®—å…œåº•å¥–åŠ±ï¼ˆå½“å®Œæ•´æµç¨‹å¤±è´¥æ—¶ä½¿ç”¨ï¼‰
    åŸºäºè®°å¿†æ•°é‡ç»™åˆ†ï¼šæ¯ä¸ªmemory 0.05åˆ†ï¼Œæœ€å¤š0.8åˆ†
    é¿å…è¿”å›0å½±å“GRPOè®­ç»ƒ
    """
    total_memories = 0
    
    for item in memory_actions:
        if not isinstance(item, dict):
            continue
        agent_type = item.get("agent_type", "")
        action = item.get("action", {})
        
        if agent_type == "core":
            # Core memory æœ‰å†…å®¹å°±ç®—1ä¸ª
            if action.get("content") or action.get("new_core_memory"):
                total_memories += 1
        else:
            # å…¶ä»–agentsè®¡ç®—operationsæ•°é‡
            agent_data = action.get(agent_type, action) if isinstance(action, dict) else {}
            operations = agent_data.get("operations", []) if isinstance(agent_data, dict) else []
            for op in operations:
                op_action = str(op.get("action", "")).upper()
                if op_action in ["ADD", "UPDATE", "MERGE"]:
                    total_memories += 1
    
    # æ¯ä¸ªmemory 0.05åˆ†ï¼Œæœ€å¤š0.8åˆ†
    reward = min(0.8, total_memories * 0.05)
    return reward


def main():
    parser = argparse.ArgumentParser(
        description="Memory API Server for RL Training",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Using OpenAI API
  python -m training.reward_server.server --api-key sk-xxx

  # Using custom OpenAI-compatible endpoint (e.g., vLLM, Azure)
  python -m training.reward_server.server --api-key your-key --base-url http://localhost:8000/v1

  # With debug mode
  python -m training.reward_server.server --api-key sk-xxx --debug
"""
    )
    parser.add_argument("--port", type=int, default=8765, help="Server port (default: 8765)")
    parser.add_argument("--host", type=str, default="0.0.0.0", help="Server host (default: 0.0.0.0)")
    parser.add_argument("--api-key", type=str, required=True, help="OpenAI API key (required)")
    parser.add_argument("--base-url", type=str, default=None, help="Custom API base URL (optional)")
    parser.add_argument("--debug", action="store_true", help="Enable debug mode")
    args = parser.parse_args()
    
    # Set environment variables from command line args
    os.environ["OPENAI_API_KEY"] = args.api_key
    if args.base_url:
        os.environ["OPENAI_BASE_URL"] = args.base_url
    
    # Enable debug mode
    global DEBUG_MODE
    if args.debug:
        DEBUG_MODE = True
    
    print("=" * 60)
    print("Memory API Server for RL Training")
    print("=" * 60)
    print(f"Host: {args.host}")
    print(f"Port: {args.port}")
    print(f"API Base: {args.base_url or 'https://api.openai.com/v1 (default)'}")
    print(f"Debug: {args.debug}")
    print("=" * 60)
    
    app.run(host=args.host, port=args.port, threaded=True)


if __name__ == "__main__":
    main()
