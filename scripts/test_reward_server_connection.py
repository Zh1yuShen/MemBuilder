#!/usr/bin/env python3
"""
RL Training Connection Test Script

æµ‹è¯•è®­ç»ƒæœºå™¨ä¸å¥–åŠ±æœåŠ¡å™¨ä¹‹é—´çš„è¿é€šæ€§ï¼Œæ¨¡æ‹ŸçœŸå® RL è®­ç»ƒçš„è¯·æ±‚æµç¨‹ã€‚
åŒ…å«å®Œæ•´çš„è®°å¿†æ„å»º + QAå›ç­” + Judgeè¯„åˆ†æµç¨‹ã€‚

Usage:
    # åŸºç¡€è¿æ¥æµ‹è¯•
    python test_reward_server_connection.py --server-url http://<server_ip>:8765
    
    # å®Œæ•´æµ‹è¯•ï¼ˆåŒ…å«çœŸå®æ•°æ®ï¼‰
    python test_reward_server_connection.py --server-url http://<server_ip>:8765 --full
    
    # ä½¿ç”¨çœŸå®parquetæ•°æ®æµ‹è¯•
    python test_reward_server_connection.py --server-url http://<server_ip>:8765 --real-data
"""

import argparse
import json
import time
import requests
from datetime import datetime


def print_banner(title):
    print("\n" + "=" * 60)
    print(f"  {title}")
    print("=" * 60)


def print_step(step_num, description):
    print(f"\n[Step {step_num}] {description}")
    print("-" * 50)


def test_health_check(server_url):
    """Test health endpoint."""
    print_step(1, "Health Check")
    
    try:
        start = time.time()
        resp = requests.get(f"{server_url}/health", timeout=10)
        latency = (time.time() - start) * 1000
        
        if resp.status_code == 200:
            data = resp.json()
            print(f"âœ… æœåŠ¡å™¨çŠ¶æ€: {data.get('status', 'unknown')}")
            print(f"âœ… æ¶ˆæ¯: {data.get('message', 'N/A')}")
            print(f"âœ… å“åº”å»¶è¿Ÿ: {latency:.2f}ms")
            return True
        else:
            print(f"âŒ HTTP çŠ¶æ€ç : {resp.status_code}")
            return False
    except requests.exceptions.ConnectionError:
        print(f"âŒ æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨: {server_url}")
        return False
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        return False


def test_build_and_qa_simple(server_url):
    """Test build_and_qa with simple data."""
    print_step(2, "Build & QA (ç®€å•æµ‹è¯•)")
    
    # æ¨¡æ‹Ÿç®€å•çš„ RL è®­ç»ƒè¯·æ±‚
    payload = {
        "session_group_id": "test_session_001",
        "memory_actions": [
            {
                "agent_type": "episodic",
                "action": {
                    "episodic": {
                        "operations": [
                            {"action": "ADD", "memory": "ç”¨æˆ·å–œæ¬¢å–å’–å•¡"}
                        ]
                    }
                }
            }
        ],
        "qa_pairs": [
            {
                "question": "ç”¨æˆ·å–œæ¬¢å–ä»€ä¹ˆé¥®æ–™ï¼Ÿ",
                "answer": "å’–å•¡"
            }
        ]
    }
    
    try:
        start = time.time()
        resp = requests.post(
            f"{server_url}/build_and_qa",
            json=payload,
            timeout=60
        )
        latency = (time.time() - start) * 1000
        
        if resp.status_code == 200:
            data = resp.json()
            print(f"âœ… è¯·æ±‚æˆåŠŸ")
            print(f"   - task_reward: {data.get('task_reward', 'N/A')}")
            print(f"   - correct: {data.get('correct', 'N/A')}/{data.get('total', 'N/A')}")
            print(f"   - retrieval_counts: {data.get('retrieval_counts', {})}")
            print(f"   - dominant_agent: {data.get('dominant_agent', 'N/A')}")
            print(f"âœ… å“åº”å»¶è¿Ÿ: {latency:.2f}ms")
            return True
        else:
            print(f"âŒ HTTP çŠ¶æ€ç : {resp.status_code}")
            print(f"âŒ å“åº”: {resp.text}")
            return False
    except requests.exceptions.Timeout:
        print(f"âŒ è¯·æ±‚è¶…æ—¶ï¼ˆ>60sï¼‰")
        return False
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        return False


def test_build_and_qa_complex(server_url):
    """Test build_and_qa with complex multi-agent data."""
    print_step(3, "Build & QA (å¤æ‚å¤š Agent æµ‹è¯•)")
    
    # æ¨¡æ‹Ÿå¤æ‚çš„å¤š Agent è®°å¿†æ“ä½œ
    payload = {
        "session_group_id": "test_session_002",
        "memory_actions": [
            {
                "agent_type": "core",
                "action": {
                    "operation": "APPEND",
                    "content": "ç”¨æˆ·å: Alice, èŒä¸š: è½¯ä»¶å·¥ç¨‹å¸ˆ"
                }
            },
            {
                "agent_type": "episodic",
                "action": {
                    "episodic": {
                        "operations": [
                            {"action": "ADD", "memory": "2024å¹´1æœˆ: Alice å®Œæˆäº†æœºå™¨å­¦ä¹ é¡¹ç›®"},
                            {"action": "ADD", "memory": "2024å¹´2æœˆ: Alice å‚åŠ äº†æŠ€æœ¯ä¼šè®®"}
                        ]
                    }
                }
            },
            {
                "agent_type": "semantic",
                "action": {
                    "semantic": {
                        "operations": [
                            {"action": "ADD", "memory": "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯"}
                        ]
                    }
                }
            },
            {
                "agent_type": "procedural",
                "action": {
                    "procedural": {
                        "operations": [
                            {"action": "ADD", "memory": "ä»£ç å®¡æŸ¥æµç¨‹: 1.æäº¤PR 2.è‡ªåŠ¨æµ‹è¯• 3.äººå·¥å®¡æ ¸"}
                        ]
                    }
                }
            }
        ],
        "qa_pairs": [
            {
                "question": "Alice åœ¨2024å¹´1æœˆåšäº†ä»€ä¹ˆé¡¹ç›®ï¼Ÿ",
                "answer": "æœºå™¨å­¦ä¹ é¡¹ç›®",
                "type": "single-session"
            },
            {
                "question": "Alice çš„èŒä¸šæ˜¯ä»€ä¹ˆï¼Ÿ",
                "answer": "è½¯ä»¶å·¥ç¨‹å¸ˆ",
                "type": "single-session"
            },
            {
                "question": "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ",
                "answer": "äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯",
                "type": "semantic"
            }
        ]
    }
    
    try:
        start = time.time()
        resp = requests.post(
            f"{server_url}/build_and_qa",
            json=payload,
            timeout=120
        )
        latency = (time.time() - start) * 1000
        
        if resp.status_code == 200:
            data = resp.json()
            print(f"âœ… è¯·æ±‚æˆåŠŸ")
            print(f"   - task_reward: {data.get('task_reward', 'N/A')}")
            print(f"   - correct: {data.get('correct', 'N/A')}/{data.get('total', 'N/A')}")
            print(f"   - retrieval_counts: {data.get('retrieval_counts', {})}")
            print(f"   - dominant_agent: {data.get('dominant_agent', 'N/A')}")
            print(f"âœ… å“åº”å»¶è¿Ÿ: {latency:.2f}ms ({latency/1000:.2f}s)")
            return True
        else:
            print(f"âŒ HTTP çŠ¶æ€ç : {resp.status_code}")
            print(f"âŒ å“åº”: {resp.text}")
            return False
    except requests.exceptions.Timeout:
        print(f"âŒ è¯·æ±‚è¶…æ—¶ï¼ˆ>120sï¼‰")
        return False
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        return False


def test_concurrent_requests(server_url, num_requests=3):
    """Test concurrent requests (simulate multi-GPU training)."""
    print_step(4, f"å¹¶å‘è¯·æ±‚æµ‹è¯• (æ¨¡æ‹Ÿ {num_requests} ä¸ª GPU å¹¶è¡Œè¯·æ±‚)")
    
    import concurrent.futures
    
    def single_request(idx):
        payload = {
            "session_group_id": f"concurrent_test_{idx}",
            "memory_actions": [
                {
                    "agent_type": "episodic",
                    "action": {
                        "episodic": {
                            "operations": [
                                {"action": "ADD", "memory": f"æµ‹è¯•è®°å¿† #{idx}"}
                            ]
                        }
                    }
                }
            ],
            "qa_pairs": [
                {"question": f"æµ‹è¯•é—®é¢˜ #{idx}", "answer": f"æµ‹è¯•ç­”æ¡ˆ #{idx}"}
            ]
        }
        
        start = time.time()
        resp = requests.post(f"{server_url}/build_and_qa", json=payload, timeout=60)
        latency = time.time() - start
        return idx, resp.status_code, latency
    
    try:
        start_all = time.time()
        with concurrent.futures.ThreadPoolExecutor(max_workers=num_requests) as executor:
            futures = [executor.submit(single_request, i) for i in range(num_requests)]
            results = [f.result() for f in concurrent.futures.as_completed(futures)]
        total_time = time.time() - start_all
        
        success_count = sum(1 for _, status, _ in results if status == 200)
        avg_latency = sum(lat for _, _, lat in results) / len(results)
        
        print(f"âœ… æˆåŠŸ: {success_count}/{num_requests}")
        print(f"âœ… å¹³å‡å»¶è¿Ÿ: {avg_latency*1000:.2f}ms")
        print(f"âœ… æ€»è€—æ—¶: {total_time*1000:.2f}ms")
        
        for idx, status, lat in sorted(results):
            status_icon = "âœ…" if status == 200 else "âŒ"
            print(f"   {status_icon} è¯·æ±‚ #{idx}: {status}, {lat*1000:.2f}ms")
        
        return success_count == num_requests
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        return False


def test_error_handling(server_url):
    """Test error handling with invalid requests."""
    print_step(5, "é”™è¯¯å¤„ç†æµ‹è¯•")
    
    # æµ‹è¯•ç©ºè¯·æ±‚
    try:
        resp = requests.post(f"{server_url}/build_and_qa", json={}, timeout=30)
        print(f"   ç©ºè¯·æ±‚å“åº”: HTTP {resp.status_code}")
    except Exception as e:
        print(f"   ç©ºè¯·æ±‚é”™è¯¯: {e}")
    
    # æµ‹è¯•æ— æ•ˆç«¯ç‚¹
    try:
        resp = requests.get(f"{server_url}/invalid_endpoint", timeout=10)
        print(f"   æ— æ•ˆç«¯ç‚¹å“åº”: HTTP {resp.status_code}")
    except Exception as e:
        print(f"   æ— æ•ˆç«¯ç‚¹é”™è¯¯: {e}")
    
    print("âœ… é”™è¯¯å¤„ç†æµ‹è¯•å®Œæˆ")
    return True


def test_with_real_data(server_url, parquet_path="data/memory_rl_train.parquet"):
    """Test with real parquet data including state_before_path."""
    print_step(6, "çœŸå®æ•°æ®å®Œæ•´æµç¨‹æµ‹è¯•ï¼ˆstate_before + è®°å¿†æ„å»º + QA + Judgeï¼‰")
    
    import sys
    from pathlib import Path
    
    # Add project root to path
    project_root = Path(__file__).resolve().parent.parent
    sys.path.insert(0, str(project_root))
    
    try:
        import datasets
    except ImportError:
        print("âŒ éœ€è¦å®‰è£… datasets åº“: pip install datasets")
        return False
    
    # Load parquet
    full_parquet_path = project_root / parquet_path
    if not full_parquet_path.exists():
        print(f"âŒ Parquet æ–‡ä»¶ä¸å­˜åœ¨: {full_parquet_path}")
        print(f"   è¯·å…ˆè¿è¡Œ: python scripts/prepare_rl_data.py")
        return False
    
    print(f"ğŸ“‚ åŠ è½½æ•°æ®: {full_parquet_path}")
    ds = datasets.load_dataset('parquet', data_files=str(full_parquet_path))['train']
    print(f"   æ€»æ ·æœ¬æ•°: {len(ds)}")
    
    # Get first sample (core agent)
    item = ds[0]
    rm = item['reward_model']
    gt = rm['ground_truth'][0] if isinstance(rm.get('ground_truth'), list) else {}
    
    state_before_path = gt.get('state_before_path', '')
    qa_questions = gt.get('qa_questions', [])
    expert_output = gt.get('expert_output', {})
    
    print(f"\nğŸ“‹ æ ·æœ¬ä¿¡æ¯:")
    print(f"   - conversation_id: {rm.get('conversation_id', 'N/A')}")
    print(f"   - session_index: {rm.get('session_index', 'N/A')}")
    print(f"   - agent_type: {rm.get('agent_type', 'N/A')}")
    print(f"   - state_before_path: {state_before_path}")
    print(f"   - qa_questions æ•°é‡: {len(qa_questions)}")
    
    if not qa_questions:
        print("âš ï¸ æ²¡æœ‰ QA questionsï¼Œè·³è¿‡æµ‹è¯•")
        return False
    
    # Prepare request with real data
    # Simulate model output (use expert output as reference)
    memory_actions = []
    for agent_type in ['core', 'episodic', 'semantic', 'procedural']:
        if agent_type == 'core':
            action_data = {'operation': 'APPEND', 'content': 'æµ‹è¯•ç”¨æˆ·ä¿¡æ¯'}
        else:
            action_data = {
                agent_type: {
                    'operations': [
                        {'action': 'ADD', 'memory': f'æµ‹è¯•{agent_type}è®°å¿†å†…å®¹'}
                    ]
                }
            }
        memory_actions.append({'agent_type': agent_type, 'action': action_data})
    
    # Build request
    payload = {
        'session_group_id': f"{rm.get('conversation_id', 'test')}_sess{rm.get('session_index', 0)}",
        'state_before_path': state_before_path,
        'memory_actions': memory_actions,
        'qa_pairs': [{'question': q['question'], 'answer': q['answer']} for q in qa_questions[:3]]
    }
    
    print(f"\nğŸš€ å‘é€è¯·æ±‚åˆ°æœåŠ¡å™¨...")
    print(f"   - state_before_path: {state_before_path}")
    print(f"   - QA pairs: {len(payload['qa_pairs'])}")
    
    try:
        start = time.time()
        resp = requests.post(
            f"{server_url}/build_and_qa",
            json=payload,
            timeout=180  # 3åˆ†é’Ÿè¶…æ—¶
        )
        latency = time.time() - start
        
        if resp.status_code == 200:
            data = resp.json()
            if data.get('success'):
                print(f"\nâœ… å®Œæ•´æµç¨‹æµ‹è¯•æˆåŠŸ!")
                print(f"   - task_reward: {data.get('task_reward', 0):.4f}")
                print(f"   - correct: {data.get('correct', 0)}/{data.get('total', 0)}")
                print(f"   - retrieval_counts: {data.get('retrieval_counts', {})}")
                print(f"   - dominant_agent: {data.get('dominant_agent', 'N/A')}")
                print(f"   - è€—æ—¶: {latency:.2f}s")
                
                # éªŒè¯æµç¨‹
                print(f"\nğŸ“Š æµç¨‹éªŒè¯:")
                print(f"   âœ… è®°å¿†åŠ è½½: state_before_path å·²å¤„ç†")
                print(f"   âœ… è®°å¿†æ„å»º: memory_actions å·²åº”ç”¨")
                print(f"   âœ… QAæœç´¢: æ£€ç´¢åˆ°ç›¸å…³è®°å¿†")
                print(f"   âœ… ç­”æ¡ˆç”Ÿæˆ: LLMç”Ÿæˆäº†å›ç­”")
                print(f"   âœ… Judgeè¯„åˆ†: è®¡ç®—äº†å‡†ç¡®ç‡")
                print(f"   âœ… å¥–åŠ±è¿”å›: task_reward = {data.get('task_reward', 0):.4f}")
                return True
            else:
                print(f"âŒ è¯·æ±‚å¤±è´¥: {data.get('error', 'unknown')}")
                return False
        else:
            print(f"âŒ HTTP çŠ¶æ€ç : {resp.status_code}")
            print(f"âŒ å“åº”: {resp.text[:500]}")
            return False
    except requests.exceptions.Timeout:
        print(f"âŒ è¯·æ±‚è¶…æ—¶ (>180s)")
        return False
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return False


def simulate_training_loop(server_url, num_steps=5):
    """Simulate a mini training loop."""
    print_step(7, f"æ¨¡æ‹Ÿè®­ç»ƒå¾ªç¯ ({num_steps} æ­¥)")
    
    print("\næ¨¡æ‹Ÿ RL è®­ç»ƒè¾“å‡º:")
    print("-" * 50)
    
    total_reward = 0
    
    for step in range(1, num_steps + 1):
        payload = {
            "session_group_id": f"train_step_{step}",
            "memory_actions": [
                {
                    "agent_type": "episodic",
                    "action": {
                        "episodic": {
                            "operations": [
                                {"action": "ADD", "memory": f"è®­ç»ƒæ­¥éª¤ {step} çš„è®°å¿†å†…å®¹"}
                            ]
                        }
                    }
                }
            ],
            "qa_pairs": [
                {"question": f"ç¬¬ {step} æ­¥çš„è®­ç»ƒå†…å®¹æ˜¯ä»€ä¹ˆï¼Ÿ", "answer": f"è®­ç»ƒæ­¥éª¤ {step}"}
            ]
        }
        
        try:
            start = time.time()
            resp = requests.post(f"{server_url}/build_and_qa", json=payload, timeout=60)
            latency = (time.time() - start) * 1000
            
            if resp.status_code == 200:
                data = resp.json()
                reward = data.get('task_reward', 0)
                total_reward += reward
                
                print(f"[{datetime.now().strftime('%H:%M:%S')}] Step {step}/{num_steps} | "
                      f"Reward: {reward:.4f} | "
                      f"Avg: {total_reward/step:.4f} | "
                      f"Latency: {latency:.0f}ms")
            else:
                print(f"[{datetime.now().strftime('%H:%M:%S')}] Step {step}/{num_steps} | "
                      f"âŒ Error: HTTP {resp.status_code}")
        except Exception as e:
            print(f"[{datetime.now().strftime('%H:%M:%S')}] Step {step}/{num_steps} | "
                  f"âŒ Error: {e}")
        
        time.sleep(0.5)  # æ¨¡æ‹Ÿè®­ç»ƒé—´éš”
    
    print("-" * 50)
    print(f"è®­ç»ƒå®Œæˆ | æ€»å¥–åŠ±: {total_reward:.4f} | å¹³å‡å¥–åŠ±: {total_reward/num_steps:.4f}")
    return True


def main():
    parser = argparse.ArgumentParser(description="RL Training Connection Test")
    parser.add_argument("--server-url", type=str, default="http://localhost:8765",
                        help="Reward server URL")
    parser.add_argument("--full", action="store_true", help="Run full test suite")
    parser.add_argument("--simulate", action="store_true", help="Run training simulation")
    parser.add_argument("--real-data", action="store_true", help="Test with real parquet data")
    parser.add_argument("--parquet", type=str, default="data/memory_rl_train.parquet",
                        help="Path to parquet file (relative to project root)")
    args = parser.parse_args()
    
    print_banner("RL Training Connection Test")
    print(f"æœåŠ¡å™¨åœ°å€: {args.server_url}")
    print(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # æµ‹è¯•ç»“æœç»Ÿè®¡
    results = {}
    
    # 1. Health Check
    results["health"] = test_health_check(args.server_url)
    
    if not results["health"]:
        print("\n" + "=" * 60)
        print("âŒ å¥åº·æ£€æŸ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥:")
        print("   1. å¥–åŠ±æœåŠ¡å™¨æ˜¯å¦å·²å¯åŠ¨")
        print("   2. ç½‘ç»œæ˜¯å¦å¯è¾¾")
        print("   3. ç«¯å£æ˜¯å¦æ­£ç¡® (8765)")
        print("   4. é˜²ç«å¢™æ˜¯å¦æ”¾è¡Œ")
        print("=" * 60)
        return
    
    # 2. Simple Build & QA
    results["simple"] = test_build_and_qa_simple(args.server_url)
    
    if args.full or args.simulate or args.real_data:
        # 3. Complex Build & QA
        results["complex"] = test_build_and_qa_complex(args.server_url)
        
        # 4. Concurrent Requests
        results["concurrent"] = test_concurrent_requests(args.server_url)
        
        # 5. Error Handling
        results["error"] = test_error_handling(args.server_url)
    
    if args.real_data:
        # 6. Real Data Test
        results["real_data"] = test_with_real_data(args.server_url, args.parquet)
    
    if args.simulate:
        # 7. Training Simulation
        results["simulate"] = simulate_training_loop(args.server_url)
    
    # æ€»ç»“
    print_banner("æµ‹è¯•æ€»ç»“")
    
    all_passed = all(results.values())
    
    for test_name, passed in results.items():
        icon = "âœ…" if passed else "âŒ"
        print(f"  {icon} {test_name}")
    
    print()
    if all_passed:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ä¸¤å°æœºå™¨è¿æ¥æ­£å¸¸ï¼Œå¯ä»¥å¼€å§‹ RL è®­ç»ƒã€‚")
        print()
        print("å¯åŠ¨è®­ç»ƒå‘½ä»¤:")
        print("-" * 50)
        print(f'REWARD_SERVER_URL="{args.server_url}" \\')
        print('MODEL_PATH="/path/to/your/model" \\')
        print('TRAIN_DATA="data/memory_rl_train.parquet" \\')
        print('./scripts/run_memory_grpo_multinode.sh')
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ä¿¡æ¯ã€‚")


if __name__ == "__main__":
    main()
